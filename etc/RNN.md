```py

# ë°ì´í„°ì…‹ ì¤€ë¹„
class Cu(Dataset):  # í•™ìŠµìš© ë°ì´í„° ì¤€ë¹„
    def __init__(self):
        # df ë°ì´í„° ì‚¬ìš©
        self.data = df[['ì‹œê°€', 'ê³ ê°€', 'ì €ê°€']].values  # ì…ë ¥ : 3ê°€ì§€
        self.label = df['ì¢…ê°€'].values  # ì •ë‹µ : ì¢…ê°€

    # ì‚¬ìš© ê°€ëŠ¥í•œ ë°ì´í„° ê°œìˆ˜
    def __len__(self):
        return len(self.data) - 30  # ì‚¬ìš© ê°€ëŠ¥í•œ ë°°ì¹˜ ê°œìˆ˜

    # ë°ì´í„°ì™€ ë¼ë²¨ ë°˜í™˜
    def __getitem__(self, i): # 30ì¼ì¹˜ ì£¼ì‹ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ê·¸ ë‹¤ìŒ ë‚ ì˜ ì£¼ì‹ ì¢…ê°€ë¥¼ ì˜ˆì¸¡í•˜ë ¤ëŠ” ëª©ì 
        data = self.data[i:i+30]  # ì…ë ¥ ë°ì´í„° 30ì¼ì¹˜(30ì¼ì¹˜ ë°ì´í„°ë¥¼ ì…ë ¥ìœ¼ë¡œ)
        label = self.label[i+30]  # ì¢…ê°€ ë°ì´í„° 30ì¼ì¹˜(ê·¸ ë‹¤ìŒë‚ ì˜ ì¢…ê°€ë¥¼ ì •ë‹µìœ¼ë¡œ)

        return data, label


# RNN í´ë˜ìŠ¤ëŠ” PyTorchì˜ nn.Moduleì„ ìƒì†ë°›ì•„ RNN ëª¨ë¸ì„ ì •ì˜
class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__() # ë¶€ëª¨ í´ë˜ìŠ¤ì¸ nn.Moduleì˜ ì´ˆê¸°í™” ë©”ì„œë“œ

        # RNNì¸µ ì •ì˜
        self.rnn = nn.RNN(input_size=3, hidden_size=8, num_layers=5, batch_first=True)
        # input_size=3 : ì…ë ¥ ë°ì´í„°ì˜ íŠ¹ì„± ìˆ˜ (ì‹œê°€, ê³ ê°€, ì €ê°€ 3ê°œ)
        # hidden_size=8 : ëª¨ë¸ì˜ "ê¸°ì–µ" ìš©ëŸ‰
        # num_layers=5 : 5ì¸µ êµ¬ì¡°

        # MLP (ì„ í˜•ì¸µ)ìœ¼ë¡œ ì¢…ê°€ ì˜ˆì¸¡
        ## 30ì¼ ë™ì•ˆ ì´ 30ê°œì˜ ê¸°ì–µ(ì¶œë ¥)ì´ ìƒê¸°ê³  ê·¸ê²Œ 8ì¹¸ì”©ì´ë‹ˆê¹Œ ğŸ‘‰ 30 Ã— 8 = 240
        self.fc1 = nn.Linear(in_features=240, out_features=64) # 30ì¼ Ã— hidden_size(8) = 240
        self.fc2 = nn.Linear(in_features=64, out_features=1) # ë§ˆì§€ë§‰ìœ¼ë¡œ ì˜ˆì¸¡í•  ê°’, ì¢…ê°€ í•œ ê°œë¥¼ ì¶œë ¥

        self.relu = nn.ReLU()  # í™œì„±í™” í•¨ìˆ˜(ìŒìˆ˜ëŠ” ë²„ë¦¬ê³  ì–‘ìˆ˜ë§Œ í†µê³¼)

    def forward(self, x, h0):
        x, hn = self.rnn(x, h0)  # RNNì¸µì˜ ì¶œë ¥(ìˆœì„œëŒ€ë¡œ RNNì„ í†µê³¼ì‹œí‚´)

        # MLPì¸µì˜ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©ë˜ê²Œ ëª¨ì–‘ ë³€ê²½
        x = torch.reshape(x, (x.shape[0], -1)) # (batch_size, 240)ë¡œ ë°”ê¿ˆ

        # MLPì¸µì„ ì´ìš©í•´ ì¢…ê°€ ì˜ˆì¸¡
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)

        # ì˜ˆì¸¡í•œ ì¢…ê°€ë¥¼ 1ì°¨ì› ë²¡í„°ë¡œ í‘œí˜„
        x = torch.flatten(x)

        return x


# í•™ìŠµ ì¤€ë¹„
device = "cuda" if torch.cuda.is_available() else "cpu" # ì»´í“¨í„°ì— ê·¸ë˜í”½ì¹´ë“œ(GPU)ê°€ ìˆìœ¼ë©´ GPU ì“°ê³  ì—†ìœ¼ë©´ CPU ì“°ê¸°
model = RNN().to(device)  # ëª¨ë¸ ì •ì˜
dataset = Cu()       # ë°ì´í„°ì…‹ ì •ì˜

# ë°°ì¹˜ í¬ê¸° ì„¤ì •
batch_size = 32
loader = DataLoader(dataset, batch_size=batch_size)  # ë°°ì¹˜ í¬ê¸° 32ë¡œ ì„¤ì •

# ìµœì í™” ì •ì˜
optim = Adam(params=model.parameters(), lr=0.0001)  # ìµœì í™” ì„¤ì •

# í•™ìŠµ ë£¨í”„
for epoch in range(200):
    iterator = tqdm.tqdm(loader)
    for data, label in iterator:
        optim.zero_grad()

        # ì´ˆê¸° ì€ë‹‰ ìƒíƒœ(ì´ˆê¸° ê¸°ì–µ)
        h0 = torch.zeros(5, data.shape[0], 8).to(device)

        # ëª¨ë¸ ì˜ˆì¸¡ê°’
        pred = model(data.type(torch.FloatTensor).to(device), h0)

        # ì†ì‹¤ ê³„ì‚°
        loss = nn.MSELoss()(pred, label.type(torch.FloatTensor).to(device))
        loss.backward()  # ì˜¤ì°¨ ì—­ì „íŒŒ
        optim.step()     # ìµœì í™” ì§„í–‰(íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸)

        iterator.set_description(f"epoch{epoch} loss:{loss.item()}")

# ëª¨ë¸ ì €ì¥
torch.save(model.state_dict(), "./rnn.pth")

# ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
loader = DataLoader(dataset, batch_size=1)  # ì˜ˆì¸¡ê°’ì„ ìœ„í•œ ë°ì´í„° ë¡œë”(ì˜ˆì¸¡í•  ë• í•˜ë‚˜ì”© ì²œì²œíˆ ì •í™•í•˜ê²Œ í™•ì¸í•˜ê³  ì‹¶ê¸° ë•Œë¬¸ì— batch_size = 1)

preds = []  # ì˜ˆì¸¡ê°’ ë¦¬ìŠ¤íŠ¸
total_loss = 0

with torch.no_grad():
    # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸°
    model.load_state_dict(torch.load("./rnn.pth", map_location=device))
    # ëª¨ë¸ì„ í•™ìŠµì‹œí‚¨ í›„ ê°€ì¥ ì˜ ë°°ìš´ ìƒíƒœ(ê°€ì¤‘ì¹˜)ë¥¼ ì €ì¥í•´ë†“ìŒ.
    # ë‚˜ì¤‘ì— ì˜ˆì¸¡ì„ í•  ë•ŒëŠ” ê·¸ ì˜ ë°°ìš´ ìƒíƒœë¥¼ ë‹¤ì‹œ ë¶ˆëŸ¬ì™€ì•¼ ë˜‘ë˜‘í•œ ëª¨ë¸ì´ ì¢…ê°€ë¥¼ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•  ìˆ˜ ìˆë‹¤.

    for data, label in loader:
        h0 = torch.zeros(5, data.shape[0], 8).to(device)  # ì´ˆê¸° ì€ë‹‰ ìƒíƒœ ì •ì˜(layer(5), ë°°ì¹˜í¬ê¸°(32), ê¸°ì–µí¬ê¸°(8))

        # ì˜ˆì¸¡ê°’ ì¶œë ¥
        pred = model(data.type(torch.FloatTensor).to(device), h0)
        preds.append(pred.item())  # ì˜ˆì¸¡ê°’ ì¶”ê°€

        # ì†ì‹¤ ê³„ì‚°
        loss = nn.MSELoss()(pred, label.type(torch.FloatTensor).to(device))
        total_loss += loss / len(loader)

# í‰ê·  ì†ì‹¤ ì¶œë ¥
print(f"Total Loss: {total_loss.item()}")

# ì˜ˆì¸¡ê°’ ê·¸ë˜í”„ ì¶œë ¥
plt.plot(preds, label="Prediction")
plt.plot(dataset.label[30:], label="Actual")
plt.legend()
plt.show()
```
