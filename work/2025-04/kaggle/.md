```py
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM, GRU
from sklearn.preprocessing import MinMaxScaler

train = df.loc[:, ["Open"]].values  # 종가 대신 시가(Open)를 사용함
scaler = MinMaxScaler(feature_range=(0, 1))  # 정규화
train_scaled = scaler.fit_transform(train)  # 0~1로 스케일링

# 타임스텝 데이터셋 생성 함수
def create_timesteps(ts=50):
    X_train, y_train = [], []
    for i in range(ts, 1258):
        X_train.append(train_scaled[i-ts:i, 0])  # 과거 ts개의 데이터를 X로
        y_train.append(train_scaled[i, 0])       # 바로 다음 시점을 y로
    X_train = np.array(X_train).reshape(-1, ts, 1)  # (샘플 수, 타임스텝, 1)
    return X_train, np.array(y_train), ts
```

### 1) RNN 모델
```py
X_train, y_train, timesteps = create_timesteps(ts=50)

modelRNN = Sequential()
modelRNN.add(SimpleRNN(timesteps, activation="relu", input_shape=(50, 1)))
modelRNN.add(Dense(1))  # 다음 시점의 가격 1개 예측
modelRNN.compile(optimizer="ADAM", loss="mse")
modelRNN.fit(X_train, y_train, epochs=100)
```

- 입력: 과거 50일간의 시가

- 출력: 다음 날 시가 (회귀)

- 모델: SimpleRNN → Dense

- 용도: 단기 시계열 예측

### 2) LSTM 모델
```py
X_train, y_train, timesteps = create_timesteps(ts=10)

model = Sequential()
model.add(LSTM(timesteps, input_shape=(10, 1)))
model.add(Dense(1))
model.compile(loss='mean_squared_error', optimizer='adam')
model.fit(X_train, y_train, epochs=50)
```

- 입력: 과거 10일 시가

- 출력: 다음 날 시가

- 모델: LSTM → Dense

### 3) GRU 모델
```py
X_train, y_train, timesteps = create_timesteps(ts=15)

model_gru_ts = Sequential()
model_gru_ts.add(GRU(timesteps, return_sequences=True, input_shape=(50, 1)))
model_gru_ts.add(GRU(50))
model_gru_ts.add(Dense(1))
model_gru_ts.compile(optimizer="ADAM", loss="mse")
model_gru_ts.fit(X_train, y_train, epochs=100)
```
- 입력: 과거 50일 시가

- 모델: GRU 2층 + Dense

- 특징: return_sequences=True로 중간층 출력 유지 → 시계열 길이 유지


---


```py
df_train = pd.read_csv(...)
df_closing = df_train['Close'].apply(lambda x : x.replace(',', '')).astype('float')
scaler = MinMaxScaler(feature_range=(0,1))
df_closing = scaler.fit_transform(df_closing.values.reshape(-1, 1))

# 시퀀스 만들기
def create_dataset(dataset, time_step=1):
    x_data, y_data = [], []
    for i in range(len(dataset)-time_step-1):
        x_data.append(dataset[i:(i+time_step), 0])
        y_data.append(dataset[i + time_step, 0])
    return np.array(x_data), np.array(y_data)

# 65% 학습, 35% 테스트로 나눔
training_size = int(len(df_closing)*0.65)
train_data = df_closing[:training_size]
test_data = df_closing[training_size:]

time_step = 100  # 과거 100일 사용
X_train, y_train = create_dataset(train_data, time_step)
X_test, ytest = create_dataset(test_data, time_step)
X_train = X_train.reshape(-1, 100, 1)
X_test = X_test.reshape(-1, 100, 1)
```


### 하이퍼파라미터 튜닝 모델 정의
```py
def build_model(hp):
    model = Sequential()
    model.add(LSTM(units = hp.Choice('layer1_units', [10~100]), return_sequences=True, input_shape=(100,1)))
    for i in range(hp.Int('num_layers', 2, 15)):                        
        model.add(LSTM(units = hp.Int('units'+str(i), 10, 150, step=10), return_sequences=True))
    model.add(LSTM(units = hp.Choice('last_lstm_units', [50, 100, 150])))
    model.add(Dropout(rate = hp.Choice('rate', [0.3~0.7])))
    model.add(Dense(1))
    model.compile(loss='mean_squared_error', optimizer='adam')
    return model
```
- 튜닝 가능한 하이퍼파라미터: LSTM 유닛 수, 층 수, 드롭아웃 비율 등

- 튜닝 도구: Keras Tuner의 RandomSearch


### 튜닝 및 학습 실행
```py
tuner = RandomSearch(build_model, ...)
tuner.search(X_train, y_train, ...)
best_model = tuner.get_best_models(1)[0]
best_model.fit(...)
```

### 예측 및 시각화
```py
train_predict = best_model.predict(X_train)
test_predict = best_model.predict(X_test)

train_predict = scaler.inverse_transform(train_predict)
test_predict = scaler.inverse_transform(test_predict)

# 미래 10일 예측
future_predictions = test_data.copy()
for i in range(100):
    next_input = future_predictions[341+i:].reshape(1,100,1)
    new_prediction = model.predict(next_input)
    future_predictions = np.append(future_predictions, new_prediction)
```
- 출력: 향후 10일간의 주가 예측

- 시각화: 전체 예측 곡선 그리기

---

1번 코드(시계열 분류 모델) 기반으로 매수/매도 이진 분류 코드 작성

### 이진 분류 LSTM 모델
```py
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import accuracy_score
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import BinaryCrossentropy
from sklearn.model_selection import train_test_split

# 데이터 불러오기 (여기에 본인 csv 경로 입력)
df = pd.read_csv("your_stock_data.csv")  # 예: 삼성전자 일별 주가 데이터

# 종가(Close) 열 가져오기 (쉼표 제거 + float 변환)
df['Close'] = df['Close'].apply(lambda x: str(x).replace(',', '')).astype(float)
close_prices = df['Close'].values.reshape(-1, 1)

# 0~1 사이 값으로 정규화 (LSTM에 필요)
scaler = MinMaxScaler(feature_range=(0, 1))
close_scaled = scaler.fit_transform(close_prices)
```

### 데이터셋 구성 함수 (입력 시퀀스와 레이블 만들기) 
```py
def create_binary_dataset(dataset, time_step=30):
    x_data, y_data = [], []
    for i in range(len(dataset) - time_step - 1):
        x_seq = dataset[i:i + time_step, 0]            # 과거 30일
        next_day = dataset[i + time_step, 0]           # 다음 날 종가
        today = dataset[i + time_step - 1, 0]          # 오늘 종가
        label = 1 if next_day > today else 0           # 상승하면 1, 하락/보합이면 0
        x_data.append(x_seq)
        y_data.append(label)
    return np.array(x_data), np.array(y_data)
```
- x_data: 과거 30일간 종가

- y_data: 다음날 종가가 오늘보다 오르면 1(매수), 아니면 0(매도)

  
### 모델 입력 데이터 만들기
```py
time_step = 30
X, y = create_binary_dataset(close_scaled, time_step)

# LSTM에 맞게 3D 형태로 reshape
X = X.reshape(X.shape[0], X.shape[1], 1)  # (샘플수, 타임스텝, 1)

# 학습/테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
```

### LSTM 분류 모델 만들기
```py
model = Sequential()
model.add(LSTM(64, return_sequences=False, input_shape=(time_step, 1)))
model.add(Dropout(0.2))  # 과적합 방지
model.add(Dense(1, activation='sigmoid'))  # 이진 분류 (확률 출력)

# 컴파일: 이진 분류니까 binary_crossentropy 사용
model.compile(loss=BinaryCrossentropy(), optimizer=Adam(0.001), metrics=['accuracy'])
```


### 모델 학습
```py
history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test), verbose=1)
```
- epochs: 학습 횟수 (30번 반복)

- batch_size: 32개씩 묶어서 학습

- validation_data: 테스트 정확도도 같이 확인


### 모델 평가 및 예측 결과 확인
```py
# 예측 확률 출력 (0~1 사이)
y_pred_prob = model.predict(X_test)

# 0.5 이상이면 매수(1), 아니면 매도(0)로 처리
y_pred = (y_pred_prob > 0.5).astype(int)

# 정확도 출력
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy: {accuracy:.4f}")

```



### 예측 결과 시각화
```py
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 4))
plt.plot(y_test[:100], label="Real (매도:0 / 매수:1)")
plt.plot(y_pred[:100], label="Predicted", linestyle='--')
plt.title("실제 vs 예측 (100개 샘플)")
plt.legend()
plt.show()

```

<br><br>

|항목|설명|
|:---:|:---:|
|문제 유형|시계열 이진 분류 (다음날 종가 상승 여부 예측)|
|입력 X|과거 30일 종가 (정규화)|
|출력 y|다음날 종가가 오르면 1(매수), 아니면 0(매도)|
|모델 구조|LSTM(64) → Dropout(0.2) → Dense(1, sigmoid)|
|손실 함수|Binary Crossentropy|
|평가 지표|Accuracy (정확도)|
|예측 결과|확률(0~1)을 0.5 기준으로 분류|


<br><br>


---

Buy, Sell, Hold로 3분류 모델

- 1 (Buy) : 종가가 다음날 0.5% 이상 상승

- 0 (Hold) : 변동 거의 없음 (-0.5% ~ +0.5%)

- 2 (Sell) : 종가가 0.5% 이상 하락


### 데이터셋 구성 함수 (3분류로 변경)
```py
def create_triple_class_dataset(dataset, time_step=30, threshold=0.005):
    x_data, y_data = [], []
    for i in range(len(dataset) - time_step - 1):
        x_seq = dataset[i:i + time_step, 0]
        today = dataset[i + time_step - 1, 0]
        next_day = dataset[i + time_step, 0]
        rate = (next_day - today) / today

        if rate > threshold:
            label = 1  # Buy
        elif rate < -threshold:
            label = 2  # Sell
        else:
            label = 0  # Hold

        x_data.append(x_seq)
        y_data.append(label)

    return np.array(x_data), np.array(y_data)

```


### 데이터 준비
```py
X, y = create_triple_class_dataset(close_scaled, time_step=30)

# 3D 형태로 변환 (LSTM 입력용)
X = X.reshape(X.shape[0], X.shape[1], 1)

# train/test 분리
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=False, test_size=0.2)

```

### LSTM 3분류 모델 만들기
```py
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout

# one-hot 인코딩 (3개 클래스)
y_train_cat = to_categorical(y_train, num_classes=3)
y_test_cat = to_categorical(y_test, num_classes=3)

model = Sequential()
model.add(LSTM(64, input_shape=(X.shape[1], 1)))
model.add(Dropout(0.2))
model.add(Dense(3, activation='softmax'))  # 3개 클래스 분류

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train, y_train_cat, epochs=30, batch_size=32, validation_data=(X_test, y_test_cat))

```

### 예측 및 평가 (정밀도, 재현율, F1 score)
```py
from sklearn.metrics import classification_report

# 예측 확률
y_pred_prob = model.predict(X_test)

# 가장 확률 높은 클래스로 예측
y_pred = np.argmax(y_pred_prob, axis=1)
y_true = np.argmax(y_test_cat, axis=1)

# 평가 리포트 출력
print(classification_report(y_true, y_pred, target_names=["Hold", "Buy", "Sell"]))
```
- precision (정밀도): "매수라고 예측한 것 중 진짜 매수일 확률"

- recall (재현율): "실제 매수 중에 얼마나 잘 맞췄나"

- f1-score: precision과 recall의 조화 평균

- support: 각 클래스 개수
